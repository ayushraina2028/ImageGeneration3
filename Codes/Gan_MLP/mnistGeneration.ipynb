{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_snippets import *\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cuda\n",
       "</pre>\n"
      ],
      "text/plain": [
       "cuda\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "from torchvision.datasets import MNIST \n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(MNIST('data', train=True, download=True, transform=transform),batch_size=64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 1]                   --\n",
      "|    └─Linear: 2-1                       [-1, 1024]                803,840\n",
      "|    └─LeakyReLU: 2-2                    [-1, 1024]                --\n",
      "|    └─Dropout: 2-3                      [-1, 1024]                --\n",
      "|    └─Linear: 2-4                       [-1, 512]                 524,800\n",
      "|    └─LeakyReLU: 2-5                    [-1, 512]                 --\n",
      "|    └─Dropout: 2-6                      [-1, 512]                 --\n",
      "|    └─Linear: 2-7                       [-1, 256]                 131,328\n",
      "|    └─LeakyReLU: 2-8                    [-1, 256]                 --\n",
      "|    └─Dropout: 2-9                      [-1, 256]                 --\n",
      "|    └─Linear: 2-10                      [-1, 1]                   257\n",
      "|    └─Sigmoid: 2-11                     [-1, 1]                   --\n",
      "==========================================================================================\n",
      "Total params: 1,460,225\n",
      "Trainable params: 1,460,225\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 2.92\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 5.57\n",
      "Estimated Total Size (MB): 5.59\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 1]                   --\n",
       "|    └─Linear: 2-1                       [-1, 1024]                803,840\n",
       "|    └─LeakyReLU: 2-2                    [-1, 1024]                --\n",
       "|    └─Dropout: 2-3                      [-1, 1024]                --\n",
       "|    └─Linear: 2-4                       [-1, 512]                 524,800\n",
       "|    └─LeakyReLU: 2-5                    [-1, 512]                 --\n",
       "|    └─Dropout: 2-6                      [-1, 512]                 --\n",
       "|    └─Linear: 2-7                       [-1, 256]                 131,328\n",
       "|    └─LeakyReLU: 2-8                    [-1, 256]                 --\n",
       "|    └─Dropout: 2-9                      [-1, 256]                 --\n",
       "|    └─Linear: 2-10                      [-1, 1]                   257\n",
       "|    └─Sigmoid: 2-11                     [-1, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 1,460,225\n",
       "Trainable params: 1,460,225\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.92\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 5.57\n",
       "Estimated Total Size (MB): 5.59\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the summary of the model \n",
    "summary(discriminator, (784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100,256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256,512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512,1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024,784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 784]                 --\n",
      "|    └─Linear: 2-1                       [-1, 256]                 25,856\n",
      "|    └─LeakyReLU: 2-2                    [-1, 256]                 --\n",
      "|    └─Linear: 2-3                       [-1, 512]                 131,584\n",
      "|    └─LeakyReLU: 2-4                    [-1, 512]                 --\n",
      "|    └─Linear: 2-5                       [-1, 1024]                525,312\n",
      "|    └─LeakyReLU: 2-6                    [-1, 1024]                --\n",
      "|    └─Linear: 2-7                       [-1, 784]                 803,600\n",
      "|    └─Tanh: 2-8                         [-1, 784]                 --\n",
      "==========================================================================================\n",
      "Total params: 1,486,352\n",
      "Trainable params: 1,486,352\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 2.97\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 5.67\n",
      "Estimated Total Size (MB): 5.69\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 784]                 --\n",
       "|    └─Linear: 2-1                       [-1, 256]                 25,856\n",
       "|    └─LeakyReLU: 2-2                    [-1, 256]                 --\n",
       "|    └─Linear: 2-3                       [-1, 512]                 131,584\n",
       "|    └─LeakyReLU: 2-4                    [-1, 512]                 --\n",
       "|    └─Linear: 2-5                       [-1, 1024]                525,312\n",
       "|    └─LeakyReLU: 2-6                    [-1, 1024]                --\n",
       "|    └─Linear: 2-7                       [-1, 784]                 803,600\n",
       "|    └─Tanh: 2-8                         [-1, 784]                 --\n",
       "==========================================================================================\n",
       "Total params: 1,486,352\n",
       "Trainable params: 1,486,352\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 2.97\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.02\n",
       "Params size (MB): 5.67\n",
       "Estimated Total Size (MB): 5.69\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator().to(device)\n",
    "summary(generator, torch.zeros(1,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Noise Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(size):\n",
    "    n = torch.randn(size, 100)\n",
    "    return n.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDiscriminator(realData, fakeData):\n",
    "    \n",
    "    # Reset the Gradients\n",
    "    d_optimizer.zero_grad()\n",
    "    \n",
    "    # predicting on real data and get the loss\n",
    "    prediction1 = discriminator(realData)\n",
    "    error1 = loss(prediction1, torch.ones(realData.size(0), 1).to(device))\n",
    "    error1.backward()\n",
    "    \n",
    "    # predicting on fake data and get the loss\n",
    "    prediction2 = discriminator(fakeData)\n",
    "    error2 = loss(prediction2, torch.zeros(fakeData.size(0), 1).to(device))\n",
    "    error2.backward()\n",
    "    \n",
    "    # update weights and return overall loss\n",
    "    d_optimizer.step()\n",
    "    return error1 + error2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(fakeData):\n",
    "    \n",
    "    # Reset the Gradients\n",
    "    g_optimizer.zero_grad()\n",
    "    \n",
    "    # prediction\n",
    "    prediction = discriminator(fakeData)\n",
    "    \n",
    "    # calculate the loss\n",
    "    error = loss(prediction, torch.ones(fakeData.size(0), 1).to(device))\n",
    "    \n",
    "    # perform backpropagation\n",
    "    error.backward()\n",
    "    g_optimizer.step()\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator().to(device)\n",
    "\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "num_epochs = 1\n",
    "\n",
    "log = Report(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1.000  g_loss: 2.034  d_loss: 0.832  (975.47s - 975.47s remaining)))))\n",
      "EPOCH: 2.000  g_loss: 1.781  d_loss: 0.869  (981.05s - 0.00s remaining)))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "idx = 0\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    N = len(data_loader)\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        real_data = images.view(len(images), -1).to(device)\n",
    "        fake_data = generator(noise(len(real_data))).to(device)\n",
    "        fake_data = fake_data.detach()\n",
    "        \n",
    "        d_loss = trainDiscriminator(real_data, fake_data)\n",
    "        fake_data = generator(noise(len(real_data))).to(device)\n",
    "        g_loss = trainGenerator(fake_data)\n",
    "        \n",
    "        # Append losses to lists\n",
    "        if(i==idx):\n",
    "            d_losses.append(d_loss.item())\n",
    "            g_losses.append(g_loss.item())\n",
    "        \n",
    "        log.record(epoch+(1+i)/N, d_loss=d_loss.item(), g_loss=g_loss.item(), end='\\r')\n",
    "    idx = idx + 1\n",
    "    log.report_avgs(epoch+1)\n",
    "\n",
    "# save d_losses and g_losses in a csv file\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'d_losses':d_losses, 'g_losses':g_losses})\n",
    "df.to_csv('losses.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import save_image\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use the Agg backend for non-GUI environments\n",
    "import torch\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "# Generate images\n",
    "z = torch.randn(256, 100).to(device)\n",
    "sample_images = generator(z).data.view(256, 1, 28, 28)\n",
    "\n",
    "# Create a grid of images\n",
    "grid = make_grid(sample_images, nrow=16, normalize=True)\n",
    "\n",
    "# Save the grid of images to a file\n",
    "save_image(grid, 'gan.png')\n",
    "\n",
    "# Comment out the following line when running as a script\n",
    "# show(grid.cpu().detach().permute(1, 2, 0), sz=5)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
